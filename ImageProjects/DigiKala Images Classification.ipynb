{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#data:\n",
        "#https://quera.org/contest/assignments/32898/problems/109977"
      ],
      "metadata": {
        "id": "LDfjwbbmVf12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6tDlZybVCjd",
        "outputId": "eaab8e20-3248-46f4-eb24-a49374028399"
      },
      "source": [
        "cd drive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENWLMtpwUQ7w"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/trainset.zip' -d '/content/drive/MyDrive/trainset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ57sC10mzCo",
        "outputId": "11eff125-a917-4935-f13d-999ecd0edb55"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# all the current subdirectory\n",
        "# p = Path('.')\n",
        "# print([x for x in p.iterdir() if x.is_dir()])\n",
        " \n",
        "data_dir =  Path(\"drive/MyDrive\")\n",
        "train_dir = data_dir / \"trainset\" / \"trainset\"\n",
        "\n",
        "training_image_paths = list(train_dir.rglob(\"*.[jJ][pP][gG]\")) + list(train_dir.rglob(\"*.[jJ][pP][eE][gG]\"))\n",
        "\n",
        "print(f'There are {len(training_image_paths)} images in the training set')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 9990 images in the training set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0LHAH-Gm_65"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import os, os.path\n",
        "\n",
        "directory =  '/content/drive/MyDrive/trainset/trainset/'\n",
        "# images = []\n",
        "# labels = []\n",
        "data_len = 9990\n",
        "images = np.zeros((data_len,224, 224,3), dtype='uint8')\n",
        "labels = np.zeros((data_len,), dtype='uint8')\n",
        "names = {}\n",
        "count = 0\n",
        "indx = 0\n",
        "unique = []\n",
        "\n",
        "shuffled_indices = random.sample(range(0, 9990), 1000)\n",
        "\n",
        "for i in range(1,11,1):\n",
        "    folder = directory+str(i)\n",
        "    for filename in os.listdir(folder):\n",
        "        print(os.path.join(folder,filename))\n",
        "        img = cv2.imread(os.path.join(folder,filename))\n",
        "#         gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        if img is not None and count in shuffled_indices:\n",
        "            img = cv2.resize(img, (224, 224),interpolation = cv2.INTER_NEAREST)\n",
        "#             data = np.array(img)\n",
        "#             print(np.shape(data))\n",
        "#             flattened = data.flatten()\n",
        "            \n",
        "            images[indx] = (img/.256)\n",
        "            labels[indx] = i\n",
        "            names[indx] = (filename)\n",
        "            indx = indx + 1\n",
        "        count = count + 1 \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivzOpAZOn6wP"
      },
      "source": [
        "import sklearn.datasets\n",
        "\n",
        "dataset = sklearn.utils.Bunch(name = (names) , data=(images), target=(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTTf20hwn8e7",
        "outputId": "205a9eb0-ae7b-48c8-fdec-a5b1e3e4fbf8"
      },
      "source": [
        "X,y = dataset['data'],dataset['target']\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(y)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9990, 224, 224, 3)\n",
            "(9990, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q07Ik9j0oBaF"
      },
      "source": [
        "def split_train_valid_test_indices(data_len,test_ratio):\n",
        "    shuffled_indices = np.random.permutation(data_len)\n",
        "    test_set_size = int(data_len*test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    valid_indices = shuffled_indices[test_set_size:test_set_size*2]\n",
        "    train_indices = shuffled_indices[test_set_size*2:]\n",
        "    return list(train_indices), list(valid_indices), list(test_indices)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqVDDM8YoJn0"
      },
      "source": [
        "train_indices , valid_indices , test_indices = split_train_valid_test_indices(X.shape[0],0.2)\n",
        "train_x = X[train_indices] \n",
        "valid_x = X[valid_indices] \n",
        "test_x = X[test_indices]\n",
        "train_y = y[train_indices] \n",
        "valid_y = y[valid_indices] \n",
        "test_y = y[test_indices]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vu7f0cZHqyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c2181f-b618-4518-9f96-33444b8054c1"
      },
      "source": [
        "# imports for the model\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2DTranspose, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# imports for the dataset\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Get a pre-built ResNet50 w/o the top layer (classifer) and input shape configured for 128 x 128\n",
        "base = ResNet50(include_top=False, input_shape=(224, 224, 3), pooling='max')\n",
        "\n",
        "# Add a new classifier (top) layer for the 10 classes in CIFAR-10\n",
        "outputs = Dense(11, activation='softmax')(base.output)\n",
        "\n",
        "# Rebuild the model with the new classifier\n",
        "resnet = Model(base.input, outputs)\n",
        "# resnet.summary()\n",
        "\n",
        "# Create the pre-stem as a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the ResNet50 model as the remaining layers and rebuild\n",
        "model.add(resnet)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['acc'])\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, batch_size=32, verbose=1, \n",
        "                    validation_data=(valid_x, valid_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "188/188 [==============================] - 74s 362ms/step - loss: 1.3152 - acc: 0.9002 - val_loss: 0.4855 - val_acc: 0.9134\n",
            "Epoch 2/5\n",
            "188/188 [==============================] - 68s 359ms/step - loss: 0.3786 - acc: 0.9161 - val_loss: 0.2603 - val_acc: 0.9229\n",
            "Epoch 3/5\n",
            "188/188 [==============================] - 63s 334ms/step - loss: 0.2012 - acc: 0.9379 - val_loss: 0.2503 - val_acc: 0.9244\n",
            "Epoch 4/5\n",
            "188/188 [==============================] - 63s 333ms/step - loss: 0.1589 - acc: 0.9530 - val_loss: 0.2807 - val_acc: 0.9269\n",
            "Epoch 5/5\n",
            "188/188 [==============================] - 67s 359ms/step - loss: 0.0998 - acc: 0.9686 - val_loss: 0.2726 - val_acc: 0.9244\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf3b81bb50>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmqe-LuWikyM",
        "outputId": "feb34bd1-3f8b-4c83-a4e8-83eee392a26a"
      },
      "source": [
        "scores = model.evaluate(test_x, test_y, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 6s 92ms/step - loss: 0.2501 - acc: 0.9354\n"
          ]
        }
      ]
    }
  ]
}